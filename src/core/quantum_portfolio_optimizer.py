#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Quantum Portfolio Optimization Engine
===================================

Advanced quantum-inspired optimization for portfolio construction and
arbitrage opportunity identification. This engine uses quantum algorithms
and quantum-inspired classical methods to solve complex optimization problems
that traditional methods cannot handle efficiently.

The system continuously optimizes portfolio allocations, identifies arbitrage
opportunities across multiple assets and timeframes, and maximizes returns
while minimizing risk through quantum computational advantages.
"""

import asyncio
import logging
import json
import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple, Union
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from pathlib import Path
import scipy.optimize as opt
from scipy.linalg import sqrtm
import cvxpy as cp
import networkx as nx
from sklearn.covariance import LedoitWolf
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# Quantum-inspired optimization libraries
try:
    import qiskit
    from qiskit_optimization import QuadraticProgram
    from qiskit_optimization.algorithms import MinimumEigenOptimizer
    from qiskit.algorithms import QAOA, VQE
    from qiskit.circuit.library import TwoLocal
    QUANTUM_AVAILABLE = True
except ImportError:
    QUANTUM_AVAILABLE = False
    logging.warning("Qiskit not available, using quantum-inspired classical algorithms")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class PortfolioOptimizationResult:
    """Portfolio optimization result"""
    weights: np.ndarray
    expected_return: float
    volatility: float
    sharpe_ratio: float
    max_drawdown: float
    var_95: float
    cvar_95: float
    diversification_ratio: float
    turnover: float
    optimization_method: str
    computation_time: float
    confidence: float
    timestamp: datetime

@dataclass
class ArbitrageOpportunity:
    """Arbitrage opportunity identification"""
    opportunity_id: str
    asset_pair: Tuple[str, str]
    spread: float
    expected_profit: float
    probability: float
    time_horizon: str
    entry_price_a: float
    entry_price_b: float
    exit_price_a: float
    exit_price_b: float
    risk_score: float
    liquidity_score: float
    execution_complexity: str
    timestamp: datetime

@dataclass
class QuantumState:
    """Quantum optimization state"""
    quantum_advantage: float
    entanglement_measure: float
    coherence_time: float
    gate_fidelity: float
    optimization_depth: int
    quantum_volume: int
    classical_fallback: bool
    computation_error: float

class QuantumPortfolioOptimizer:
    """
    Quantum-enhanced portfolio optimization engine that leverages quantum
    computing principles for superior optimization performance.
    """
    
    def __init__(self, config_file: str = "config/quantum_optimizer_config.json"):
        self.config = self._load_config(config_file)
        self.portfolio_history = []
        self.arbitrage_opportunities = []
        self.quantum_state = None
        
        # Portfolio parameters
        self.assets = []
        self.returns_data = pd.DataFrame()
        self.covariance_matrix = None
        self.expected_returns = None
        self.current_weights = None
        
        # Quantum circuits and optimizers
        self.quantum_optimizer = None
        self.vqe_circuit = None
        self.qaoa_circuit = None
        
        # Risk models
        self.risk_factors = {}
        self.factor_loadings = None
        self.idiosyncratic_risk = None
        
        # Transaction cost models
        self.transaction_costs = {}
        self.market_impact_model = None
        
        # Optimization constraints
        self.constraints = {
            'max_weight': 0.1,  # Maximum 10% in any single asset
            'min_weight': 0.0,  # No short selling by default
            'max_turnover': 0.5,  # Maximum 50% turnover
            'max_concentration': 0.3,  # Maximum 30% in any sector
            'min_diversification': 20,  # Minimum 20 assets
            'max_leverage': 1.0  # No leverage by default
        }
        
        # Performance tracking
        self.performance_metrics = {
            'total_return': 0.0,
            'annualized_return': 0.0,
            'volatility': 0.0,
            'sharpe_ratio': 0.0,
            'max_drawdown': 0.0,
            'calmar_ratio': 0.0,
            'information_ratio': 0.0,
            'tracking_error': 0.0
        }
        
        self.initialize_quantum_systems()
    
    def _load_config(self, config_file: str) -> Dict[str, Any]:
        """Load quantum optimizer configuration"""
        default_config = {
            "quantum_settings": {
                "use_quantum": QUANTUM_AVAILABLE,
                "quantum_backend": "qasm_simulator",
                "optimization_method": "VQE",  # VQE, QAOA, or classical
                "max_iterations": 1000,
                "convergence_threshold": 1e-6,
                "quantum_depth": 4,
                "entanglement_strategy": "full"
            },
            "portfolio_settings": {
                "rebalancing_frequency": "daily",
                "lookback_window": 252,  # 1 year
                "min_history_days": 60,
                "risk_free_rate": 0.02,
                "target_volatility": 0.15,
                "max_assets": 100,
                "min_liquidity": 1e6  # Minimum $1M daily volume
            },
            "optimization_objectives": {
                "return_weight": 0.6,
                "risk_weight": 0.3,
                "diversification_weight": 0.1,
                "transaction_cost_weight": 0.05,
                "esg_weight": 0.0,
                "momentum_weight": 0.1,
                "mean_reversion_weight": 0.1
            },
            "risk_management": {
                "var_confidence": 0.95,
                "cvar_confidence": 0.95,
                "stress_test_scenarios": 1000,
                "correlation_threshold": 0.8,
                "concentration_limit": 0.1,
                "sector_limit": 0.3
            },
            "arbitrage_detection": {
                "min_spread": 0.001,  # 0.1% minimum spread
                "max_execution_time": 300,  # 5 minutes
                "min_probability": 0.7,
                "transaction_cost_factor": 0.001,
                "slippage_factor": 0.0005,
                "cross_asset_pairs": True,
                "statistical_arbitrage": True
            }
        }
        
        if Path(config_file).exists():
            try:
                with open(config_file, 'r') as f:
                    user_config = json.load(f)
                # Deep merge configurations
                for key, value in user_config.items():
                    if key in default_config and isinstance(value, dict):
                        default_config[key].update(value)
                    else:
                        default_config[key] = value
            except Exception as e:
                logger.error(f"Error loading config: {e}, using defaults")
        
        return default_config
    
    def initialize_quantum_systems(self):
        """Initialize quantum computing systems"""
        try:
            if QUANTUM_AVAILABLE and self.config['quantum_settings']['use_quantum']:
                logger.info("âš›ï¸ Initializing quantum optimization systems...")
                
                # Initialize quantum backend
                from qiskit import Aer
                self.quantum_backend = Aer.get_backend(self.config['quantum_settings']['quantum_backend'])
                
                # Initialize VQE for continuous optimization
                self.vqe_circuit = TwoLocal(
                    num_qubits=8,  # Start with 8 qubits
                    rotation_blocks='ry',
                    entanglement_blocks='cz',
                    entanglement=self.config['quantum_settings']['entanglement_strategy'],
                    reps=self.config['quantum_settings']['quantum_depth']
                )
                
                # Initialize quantum state tracking
                self.quantum_state = QuantumState(
                    quantum_advantage=0.0,
                    entanglement_measure=0.0,
                    coherence_time=100.0,  # microseconds
                    gate_fidelity=0.99,
                    optimization_depth=self.config['quantum_settings']['quantum_depth'],
                    quantum_volume=32,  # Estimated quantum volume
                    classical_fallback=False,
                    computation_error=0.01
                )
                
                logger.info("âœ… Quantum systems initialized successfully")
            else:
                logger.info("ðŸ”§ Using classical optimization (quantum not available)")
                self.quantum_state = QuantumState(
                    quantum_advantage=0.0,
                    entanglement_measure=0.0,
                    coherence_time=0.0,
                    gate_fidelity=0.0,
                    optimization_depth=0,
                    quantum_volume=0,
                    classical_fallback=True,
                    computation_error=0.001
                )
                
        except Exception as e:
            logger.error(f"âŒ Error initializing quantum systems: {e}")
            self._initialize_classical_fallback()
    
    def _initialize_classical_fallback(self):
        """Initialize classical optimization fallback"""
        logger.info("ðŸ”„ Initializing classical optimization fallback...")
        
        self.quantum_state = QuantumState(
            quantum_advantage=0.0,
            entanglement_measure=0.0,
            coherence_time=0.0,
            gate_fidelity=0.0,
            optimization_depth=0,
            quantum_volume=0,
            classical_fallback=True,
            computation_error=0.001
        )
    
    async def optimize_portfolio(self, assets: List[str], 
                               returns_data: pd.DataFrame,
                               current_weights: Optional[np.ndarray] = None) -> PortfolioOptimizationResult:
        """Optimize portfolio using quantum algorithms"""
        start_time = datetime.now()
        
        try:
            logger.info(f"ðŸš€ Starting quantum portfolio optimization for {len(assets)} assets...")
            
            # Prepare data
            self.assets = assets
            self.returns_data = returns_data
            self.current_weights = current_weights if current_weights is not None else np.ones(len(assets)) / len(assets)
            
            # Calculate expected returns and covariance
            await self._prepare_optimization_data()
            
            # Choose optimization method
            if self.quantum_state.classical_fallback:
                result = await self._classical_optimization()
            else:
                result = await self._quantum_optimization()
            
            # Calculate performance metrics
            result = await self._calculate_portfolio_metrics(result)
            
            # Store result
            self.portfolio_history.append(asdict(result))
            
            computation_time = (datetime.now() - start_time).total_seconds()
            result.computation_time = computation_time
            
            logger.info(f"âœ… Portfolio optimization completed in {computation_time:.2f}s")
            logger.info(f"ðŸ“Š Expected return: {result.expected_return:.2%}, Volatility: {result.volatility:.2%}, Sharpe: {result.sharpe_ratio:.2f}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Error in portfolio optimization: {e}")
            # Return current weights as fallback
            return PortfolioOptimizationResult(
                weights=self.current_weights,
                expected_return=0.0,
                volatility=0.0,
                sharpe_ratio=0.0,
                max_drawdown=0.0,
                var_95=0.0,
                cvar_95=0.0,
                diversification_ratio=0.0,
                turnover=0.0,
                optimization_method="fallback",
                computation_time=0.0,
                confidence=0.0,
                timestamp=datetime.now()
            )
    
    async def _prepare_optimization_data(self):
        """Prepare data for optimization"""
        try:
            # Calculate expected returns using multiple methods
            self.expected_returns = await self._calculate_expected_returns()
            
            # Estimate covariance matrix with shrinkage
            self.covariance_matrix = await self._estimate_covariance_matrix()
            
            # Calculate risk factors
            await self._calculate_risk_factors()
            
            # Estimate transaction costs
            await self._estimate_transaction_costs()
            
        except Exception as e:
            logger.error(f"Error preparing optimization data: {e}")
            raise
    
    async def _calculate_expected_returns(self) -> np.ndarray:
        """Calculate expected returns using multiple methods"""
        try:
            returns = self.returns_data[self.assets].dropna()
            
            # Method 1: Historical mean
            historical_mean = returns.mean().values
            
            # Method 2: Exponentially weighted mean
            ewm_mean = returns.ewm(span=60).mean().iloc[-1].values
            
            # Method 3: Momentum-adjusted returns
            momentum_factor = returns.rolling(20).mean().iloc[-1].values
            
            # Method 4: Mean reversion factor
            long_term_mean = returns.rolling(252).mean().iloc[-1].values
            reversion_factor = long_term_mean - returns.rolling(5).mean().iloc[-1].values
            
            # Combine methods with weights from config
            weights = self.config['optimization_objectives']
            expected_returns = (
                0.3 * historical_mean +
                0.3 * ewm_mean +
                weights['momentum_weight'] * momentum_factor +
                weights['mean_reversion_weight'] * reversion_factor
            )
            
            # Annualize returns
            expected_returns = expected_returns * 252
            
            logger.info(f"ðŸ“ˆ Expected returns calculated: mean={np.mean(expected_returns):.2%}, std={np.std(expected_returns):.2%}")
            
            return expected_returns
            
        except Exception as e:
            logger.error(f"Error calculating expected returns: {e}")
            # Fallback to zero returns
            return np.zeros(len(self.assets))
    
    async def _estimate_covariance_matrix(self) -> np.ndarray:
        """Estimate covariance matrix with advanced techniques"""
        try:
            returns = self.returns_data[self.assets].dropna()
            
            # Use Ledoit-Wolf shrinkage estimator
            lw = LedoitWolf()
            cov_matrix = lw.fit(returns).covariance_
            
            # Annualize covariance
            cov_matrix = cov_matrix * 252
            
            # Ensure positive definite
            eigenvals, eigenvecs = np.linalg.eigh(cov_matrix)
            eigenvals = np.maximum(eigenvals, 1e-8)  # Floor eigenvalues
            cov_matrix = eigenvecs @ np.diag(eigenvals) @ eigenvecs.T
            
            logger.info(f"ðŸ“Š Covariance matrix estimated: condition number={np.linalg.cond(cov_matrix):.2f}")
            
            return cov_matrix
            
        except Exception as e:
            logger.error(f"Error estimating covariance matrix: {e}")
            # Fallback to identity matrix
            return np.eye(len(self.assets)) * 0.04  # 20% vol assumption
    
    async def _calculate_risk_factors(self):
        """Calculate risk factor exposures"""
        try:
            # Simple factor model for demonstration
            # In production, use more sophisticated factor models
            returns = self.returns_data[self.assets].dropna()
            
            # Market factor (first principal component)
            u, s, vt = np.linalg.svd(returns.T, full_matrices=False)
            market_factor = vt[0]  # First principal component
            
            # Calculate factor loadings
            self.factor_loadings = np.outer(returns.corrwith(pd.Series(market_factor)), np.ones(len(self.assets)))
            
            # Idiosyncratic risk
            self.idiosyncratic_risk = np.diag(self.covariance_matrix) - np.square(self.factor_loadings[:, 0])
            self.idiosyncratic_risk = np.maximum(self.idiosyncratic_risk, 0.0001)  # Floor at 1bp
            
        except Exception as e:
            logger.error(f"Error calculating risk factors: {e}")
            self.factor_loadings = np.ones((len(self.assets), 1))
            self.idiosyncratic_risk = np.ones(len(self.assets)) * 0.01
    
    async def _estimate_transaction_costs(self):
        """Estimate transaction costs for each asset"""
        try:
            # Simple transaction cost model
            # In production, use more sophisticated models based on market cap, liquidity, etc.
            base_cost = self.config['arbitrage_detection']['transaction_cost_factor']
            
            self.transaction_costs = {
                asset: base_cost for asset in self.assets
            }
            
            # Market impact model (square root law)
            self.market_impact_model = lambda volume, adv: 0.1 * np.sqrt(volume / adv)
            
        except Exception as e:
            logger.error(f"Error estimating transaction costs: {e}")
            self.transaction_costs = {asset: 0.001 for asset in self.assets}
    
    async def _quantum_optimization(self) -> PortfolioOptimizationResult:
        """Perform quantum portfolio optimization"""
        try:
            logger.info("âš›ï¸ Running quantum portfolio optimization...")
            
            if not QUANTUM_AVAILABLE:
                logger.warning("Quantum libraries not available, falling back to classical")
                return await self._classical_optimization()
            
            # Formulate as QUBO (Quadratic Unconstrained Binary Optimization)
            n_assets = len(self.assets)
            n_bins = 10  # Number of weight bins per asset
            
            # Create quadratic program
            qp = QuadraticProgram('portfolio_optimization')
            
            # Add binary variables for weight discretization
            for i in range(n_assets):
                for j in range(n_bins):
                    qp.binary_var(f'w_{i}_{j}')
            
            # Objective: maximize Sharpe ratio approximation
            # This is a simplified QUBO formulation
            risk_penalty = 1.0
            return_reward = 2.0
            
            # Add objective coefficients
            for i in range(n_assets):
                for j in range(n_bins):
                    weight = j / n_bins
                    return_contrib = return_reward * self.expected_returns[i] * weight
                    risk_contrib = risk_penalty * self.covariance_matrix[i, i] * weight * weight
                    qp.minimize(linear={f'w_{i}_{j}': -(return_contrib - risk_contrib)})
            
            # Add constraints (simplified)
            # Constraint: sum of weights = 1
            linear_constraint = {}
            for i in range(n_assets):
                for j in range(n_bins):
                    linear_constraint[f'w_{i}_{j}'] = j / n_bins
            qp.linear_constraint(linear=linear_constraint, sense='==', rhs=1.0, name='budget')
            
            # Set up VQE optimizer
            from qiskit.algorithms.optimizers import SLSQP
            optimizer = SLSQP(maxiter=self.config['quantum_settings']['max_iterations'])
            
            vqe = VQE(
                ansatz=self.vqe_circuit,
                optimizer=optimizer,
                quantum_instance=self.quantum_backend
            )
            
            # Solve using quantum algorithm
            min_eigen_optimizer = MinimumEigenOptimizer(vqe)
            quantum_result = min_eigen_optimizer.solve(qp)
            
            # Extract weights from quantum solution
            weights = self._extract_weights_from_quantum_result(quantum_result, n_assets, n_bins)
            
            # Calculate metrics
            expected_return = np.dot(weights, self.expected_returns)
            volatility = np.sqrt(np.dot(weights, np.dot(self.covariance_matrix, weights)))
            sharpe_ratio = expected_return / volatility if volatility > 0 else 0
            
            # Update quantum state
            self.quantum_state.quantum_advantage = max(0, sharpe_ratio - 1.0)  # Advantage over naive
            self.quantum_state.entanglement_measure = self._calculate_entanglement_measure(quantum_result)
            
            result = PortfolioOptimizationResult(
                weights=weights,
                expected_return=expected_return,
                volatility=volatility,
                sharpe_ratio=sharpe_ratio,
                max_drawdown=0.0,  # Will be calculated later
                var_95=0.0,
                cvar_95=0.0,
                diversification_ratio=0.0,
                turnover=0.0,
                optimization_method="quantum_vqe",
                computation_time=0.0,
                confidence=0.8,
                timestamp=datetime.now()
            )
            
            logger.info(f"âš›ï¸ Quantum optimization completed with Sharpe ratio: {sharpe_ratio:.2f}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Quantum optimization failed: {e}")
            logger.info("ðŸ”„ Falling back to classical optimization")
            return await self._classical_optimization()
    
    def _extract_weights_from_quantum_result(self, result, n_assets: int, n_bins: int) -> np.ndarray:
        """Extract portfolio weights from quantum optimization result"""
        try:
            weights = np.zeros(n_assets)
            
            if hasattr(result, 'x'):
                solution = result.x
                for i in range(n_assets):
                    for j in range(n_bins):
                        var_name = f'w_{i}_{j}'
                        if var_name in solution:
                            if solution[var_name] > 0.5:  # Binary variable is "on"
                                weights[i] = j / n_bins
                                break
            
            # Normalize weights
            if np.sum(weights) > 0:
                weights = weights / np.sum(weights)
            else:
                weights = np.ones(n_assets) / n_assets
            
            return weights
            
        except Exception as e:
            logger.error(f"Error extracting weights from quantum result: {e}")
            return np.ones(n_assets) / n_assets
    
    def _calculate_entanglement_measure(self, quantum_result) -> float:
        """Calculate entanglement measure from quantum result"""
        try:
            # Simplified entanglement measure
            # In practice, this would analyze the quantum state
            return 0.5  # Placeholder
        except:
            return 0.0
    
    async def _classical_optimization(self) -> PortfolioOptimizationResult:
        """Perform classical portfolio optimization with advanced techniques"""
        try:
            logger.info("ðŸ”§ Running advanced classical portfolio optimization...")
            
            n_assets = len(self.assets)
            
            # Multiple optimization approaches
            results = []
            
            # 1. Mean-Variance Optimization
            mv_result = await self._mean_variance_optimization()
            results.append(('mean_variance', mv_result))
            
            # 2. Risk Parity
            rp_result = await self._risk_parity_optimization()
            results.append(('risk_parity', rp_result))
            
            # 3. Black-Litterman
            bl_result = await self._black_litterman_optimization()
            results.append(('black_litterman', bl_result))
            
            # 4. Minimum Variance
            minvar_result = await self._minimum_variance_optimization()
            results.append(('minimum_variance', minvar_result))
            
            # 5. Maximum Diversification
            maxdiv_result = await self._maximum_diversification_optimization()
            results.append(('maximum_diversification', maxdiv_result))
            
            # Choose best result based on risk-adjusted return
            best_method, best_result = max(results, key=lambda x: x[1].sharpe_ratio if x[1].sharpe_ratio > 0 else -1)
            
            best_result.optimization_method = f"classical_{best_method}"
            
            logger.info(f"ðŸŽ¯ Best classical method: {best_method} with Sharpe ratio: {best_result.sharpe_ratio:.2f}")
            
            return best_result
            
        except Exception as e:
            logger.error(f"âŒ Classical optimization failed: {e}")
            # Ultimate fallback
            return await self._equal_weight_fallback()
    
    async def _mean_variance_optimization(self) -> PortfolioOptimizationResult:
        """Mean-variance optimization with constraints"""
        try:
            n_assets = len(self.assets)
            
            # Decision variables
            w = cp.Variable(n_assets)
            
            # Objective: maximize utility (return - risk_aversion * variance)
            risk_aversion = 1.0 / self.config['portfolio_settings']['target_volatility']**2
            utility = self.expected_returns.T @ w - 0.5 * risk_aversion * cp.quad_form(w, self.covariance_matrix)
            
            # Constraints
            constraints = [
                cp.sum(w) == 1,  # Budget constraint
                w >= self.constraints['min_weight'],  # No short selling
                w <= self.constraints['max_weight'],  # Maximum weight
            ]
            
            # Transaction cost constraint
            if self.current_weights is not None:
                turnover = cp.norm(w - self.current_weights, 1)
                constraints.append(turnover <= self.constraints['max_turnover'])
            
            # Solve optimization
            problem = cp.Problem(cp.Maximize(utility), constraints)
            problem.solve(solver=cp.ECOS, verbose=False)
            
            if problem.status == cp.OPTIMAL:
                weights = w.value
                weights = np.maximum(weights, 0)  # Ensure non-negative
                weights = weights / np.sum(weights)  # Normalize
            else:
                logger.warning(f"Mean-variance optimization failed with status: {problem.status}")
                weights = np.ones(n_assets) / n_assets
            
            # Calculate metrics
            expected_return = np.dot(weights, self.expected_returns)
            volatility = np.sqrt(np.dot(weights, np.dot(self.covariance_matrix, weights)))
            sharpe_ratio = expected_return / volatility if volatility > 0 else 0
            
            return PortfolioOptimizationResult(
                weights=weights,
                expected_return=expected_return,
                volatility=volatility,
                sharpe_ratio=sharpe_ratio,
                max_drawdown=0.0,
                var_95=0.0,
                cvar_95=0.0,
                diversification_ratio=0.0,
                turnover=0.0,
                optimization_method="mean_variance",
                computation_time=0.0,
                confidence=0.7,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"Error in mean-variance optimization: {e}")
            return await self._equal_weight_fallback()
    
    async def _risk_parity_optimization(self) -> PortfolioOptimizationResult:
        """Risk parity optimization"""
        try:
            n_assets = len(self.assets)
            
            def risk_parity_objective(weights):
                """Risk parity objective function"""
                weights = np.array(weights)
                portfolio_vol = np.sqrt(np.dot(weights, np.dot(self.covariance_matrix, weights)))
                
                # Risk contributions
                marginal_risk = np.dot(self.covariance_matrix, weights) / portfolio_vol
                risk_contributions = weights * marginal_risk
                
                # Target: equal risk contributions
                target_risk = np.ones(n_assets) / n_assets
                
                # Objective: minimize sum of squared deviations from equal risk
                return np.sum((risk_contributions - target_risk * np.sum(risk_contributions))**2)
            
            # Constraints
            constraints = [
                {'type': 'eq', 'fun': lambda w: np.sum(w) - 1},  # Budget
            ]
            
            bounds = [(self.constraints['min_weight'], self.constraints['max_weight']) for _ in range(n_assets)]
            
            # Initial guess
            x0 = np.ones(n_assets) / n_assets
            
            # Optimize
            result = opt.minimize(
                risk_parity_objective,
                x0,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints,
                options={'ftol': 1e-9, 'disp': False}
            )
            
            if result.success:
                weights = result.x
                weights = np.maximum(weights, 0)
                weights = weights / np.sum(weights)
            else:
                logger.warning("Risk parity optimization failed")
                weights = np.ones(n_assets) / n_assets
            
            # Calculate metrics
            expected_return = np.dot(weights, self.expected_returns)
            volatility = np.sqrt(np.dot(weights, np.dot(self.covariance_matrix, weights)))
            sharpe_ratio = expected_return / volatility if volatility > 0 else 0
            
            return PortfolioOptimizationResult(
                weights=weights,
                expected_return=expected_return,
                volatility=volatility,
                sharpe_ratio=sharpe_ratio,
                max_drawdown=0.0,
                var_95=0.0,
                cvar_95=0.0,
                diversification_ratio=0.0,
                turnover=0.0,
                optimization_method="risk_parity",
                computation_time=0.0,
                confidence=0.6,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"Error in risk parity optimization: {e}")
            return await self._equal_weight_fallback()
    
    async def _black_litterman_optimization(self) -> PortfolioOptimizationResult:
        """Black-Litterman optimization"""
        try:
            n_assets = len(self.assets)
            
            # Market capitalization weights as prior (simplified)
            market_weights = np.ones(n_assets) / n_assets  # Equal weight as proxy
            
            # Risk aversion parameter
            risk_aversion = 3.0
            
            # Implied returns from market weights
            pi = risk_aversion * np.dot(self.covariance_matrix, market_weights)
            
            # Investor views (simplified - momentum views)
            # View: assets with positive momentum will outperform
            returns = self.returns_data[self.assets].dropna()
            momentum = returns.rolling(20).mean().iloc[-1].values
            
            # Create picking matrix (simplified)
            P = np.eye(n_assets)  # Each view is about individual assets
            
            # View portfolio returns (momentum-based)
            Q = momentum * 0.01  # Scale momentum to reasonable return expectations
            
            # Uncertainty in views
            omega = np.eye(n_assets) * 0.01  # 1% uncertainty
            
            # Black-Litterman formula
            tau = 0.1  # Scaling factor
            
            # Posterior covariance
            M1 = np.linalg.inv(tau * self.covariance_matrix)
            M2 = np.dot(P.T, np.dot(np.linalg.inv(omega), P))
            post_cov = np.linalg.inv(M1 + M2)
            
            # Posterior returns
            mu1 = np.dot(M1, pi)
            mu2 = np.dot(P.T, np.dot(np.linalg.inv(omega), Q))
            post_returns = np.dot(post_cov, mu1 + mu2)
            
            # Optimize with Black-Litterman inputs
            inv_cov = np.linalg.inv(self.covariance_matrix)
            weights = np.dot(inv_cov, post_returns) / risk_aversion
            
            # Normalize
            weights = weights / np.sum(weights)
            weights = np.maximum(weights, 0)  # No short selling
            weights = weights / np.sum(weights)  # Renormalize
            
            # Calculate metrics
            expected_return = np.dot(weights, self.expected_returns)
            volatility = np.sqrt(np.dot(weights, np.dot(self.covariance_matrix, weights)))
            sharpe_ratio = expected_return / volatility if volatility > 0 else 0
            
            return PortfolioOptimizationResult(
                weights=weights,
                expected_return=expected_return,
                volatility=volatility,
                sharpe_ratio=sharpe_ratio,
                max_drawdown=0.0,
                var_95=0.0,
                cvar_95=0.0,
                diversification_ratio=0.0,
                turnover=0.0,
                optimization_method="black_litterman",
                computation_time=0.0,
                confidence=0.6,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"Error in Black-Litterman optimization: {e}")
            return await self._equal_weight_fallback()
    
    async def _minimum_variance_optimization(self) -> PortfolioOptimizationResult:
        """Minimum variance optimization"""
        try:
            n_assets = len(self.assets)
            
            # Decision variables
            w = cp.Variable(n_assets)
            
            # Objective: minimize variance
            variance = cp.quad_form(w, self.covariance_matrix)
            
            # Constraints
            constraints = [
                cp.sum(w) == 1,  # Budget constraint
                w >= self.constraints['min_weight'],
                w <= self.constraints['max_weight']
            ]
            
            # Solve
            problem = cp.Problem(cp.Minimize(variance), constraints)
            problem.solve(solver=cp.ECOS, verbose=False)
            
            if problem.status == cp.OPTIMAL:
                weights = w.value
                weights = np.maximum(weights, 0)
                weights = weights / np.sum(weights)
            else:
                weights = np.ones(n_assets) / n_assets
            
            # Calculate metrics
            expected_return = np.dot(weights, self.expected_returns)
            volatility = np.sqrt(np.dot(weights, np.dot(self.covariance_matrix, weights)))
            sharpe_ratio = expected_return / volatility if volatility > 0 else 0
            
            return PortfolioOptimizationResult(
                weights=weights,
                expected_return=expected_return,
                volatility=volatility,
                sharpe_ratio=sharpe_ratio,
                max_drawdown=0.0,
                var_95=0.0,
                cvar_95=0.0,
                diversification_ratio=0.0,
                turnover=0.0,
                optimization_method="minimum_variance",
                computation_time=0.0,
                confidence=0.8,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"Error in minimum variance optimization: {e}")
            return await self._equal_weight_fallback()
    
    async def _maximum_diversification_optimization(self) -> PortfolioOptimizationResult:
        """Maximum diversification optimization"""
        try:
            n_assets = len(self.assets)
            
            def diversification_ratio(weights):
                """Calculate diversification ratio"""
                weights = np.array(weights)
                portfolio_vol = np.sqrt(np.dot(weights, np.dot(self.covariance_matrix, weights)))
                weighted_vol = np.dot(weights, np.sqrt(np.diag(self.covariance_matrix)))
                return -weighted_vol / portfolio_vol  # Negative for minimization
            
            # Constraints
            constraints = [
                {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}
            ]
            
            bounds = [(self.constraints['min_weight'], self.constraints['max_weight']) for _ in range(n_assets)]
            
            # Initial guess
            x0 = np.ones(n_assets) / n_assets
            
            # Optimize
            result = opt.minimize(
                diversification_ratio,
                x0,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints,
                options={'ftol': 1e-9, 'disp': False}
            )
            
            if result.success:
                weights = result.x
                weights = np.maximum(weights, 0)
                weights = weights / np.sum(weights)
            else:
                weights = np.ones(n_assets) / n_assets
            
            # Calculate metrics
            expected_return = np.dot(weights, self.expected_returns)
            volatility = np.sqrt(np.dot(weights, np.dot(self.covariance_matrix, weights)))
            sharpe_ratio = expected_return / volatility if volatility > 0 else 0
            
            return PortfolioOptimizationResult(
                weights=weights,
                expected_return=expected_return,
                volatility=volatility,
                sharpe_ratio=sharpe_ratio,
                max_drawdown=0.0,
                var_95=0.0,
                cvar_95=0.0,
                diversification_ratio=0.0,
                turnover=0.0,
                optimization_method="maximum_diversification",
                computation_time=0.0,
                confidence=0.7,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"Error in maximum diversification optimization: {e}")
            return await self._equal_weight_fallback()
    
    async def _equal_weight_fallback(self) -> PortfolioOptimizationResult:
        """Fallback to equal weight portfolio"""
        logger.info("ðŸ“Š Using equal weight fallback")
        
        n_assets = len(self.assets)
        weights = np.ones(n_assets) / n_assets
        
        expected_return = np.dot(weights, self.expected_returns)
        volatility = np.sqrt(np.dot(weights, np.dot(self.covariance_matrix, weights)))
        sharpe_ratio = expected_return / volatility if volatility > 0 else 0
        
        return PortfolioOptimizationResult(
            weights=weights,
            expected_return=expected_return,
            volatility=volatility,
            sharpe_ratio=sharpe_ratio,
            max_drawdown=0.0,
            var_95=0.0,
            cvar_95=0.0,
            diversification_ratio=0.0,
            turnover=0.0,
            optimization_method="equal_weight",
            computation_time=0.0,
            confidence=0.5,
            timestamp=datetime.now()
        )
    
    async def _calculate_portfolio_metrics(self, result: PortfolioOptimizationResult) -> PortfolioOptimizationResult:
        """Calculate comprehensive portfolio metrics"""
        try:
            weights = result.weights
            
            # VaR and CVaR calculation
            returns = self.returns_data[self.assets].dropna()
            portfolio_returns = (returns * weights).sum(axis=1)
            
            # Value at Risk (95% confidence)
            var_95 = np.percentile(portfolio_returns, 5)
            result.var_95 = var_95
            
            # Conditional Value at Risk (Expected Shortfall)
            cvar_95 = portfolio_returns[portfolio_returns <= var_95].mean()
            result.cvar_95 = cvar_95
            
            # Maximum Drawdown
            cumulative_returns = (1 + portfolio_returns).cumprod()
            running_max = cumulative_returns.expanding().max()
            drawdown = (cumulative_returns - running_max) / running_max
            result.max_drawdown = drawdown.min()
            
            # Diversification Ratio
            portfolio_vol = result.volatility
            weighted_vol = np.dot(weights, np.sqrt(np.diag(self.covariance_matrix)))
            result.diversification_ratio = weighted_vol / portfolio_vol if portfolio_vol > 0 else 1
            
            # Turnover (if current weights available)
            if self.current_weights is not None:
                result.turnover = np.sum(np.abs(weights - self.current_weights))
            
            # Confidence based on optimization method and data quality
            data_quality = len(returns) / 252  # Years of data
            method_confidence = {
                'quantum_vqe': 0.9,
                'classical_mean_variance': 0.8,
                'classical_risk_parity': 0.7,
                'classical_black_litterman': 0.7,
                'classical_minimum_variance': 0.8,
                'classical_maximum_diversification': 0.7,
                'equal_weight': 0.5
            }
            
            base_confidence = method_confidence.get(result.optimization_method, 0.5)
            result.confidence = min(0.95, base_confidence * min(1.0, data_quality))
            
            return result
            
        except Exception as e:
            logger.error(f"Error calculating portfolio metrics: {e}")
            return result
    
    async def detect_arbitrage_opportunities(self, market_data: Dict[str, Any]) -> List[ArbitrageOpportunity]:
        """Detect arbitrage opportunities across assets"""
        try:
            logger.info("ðŸ” Scanning for arbitrage opportunities...")
            
            opportunities = []
            
            # Statistical arbitrage
            stat_arb_opportunities = await self._detect_statistical_arbitrage(market_data)
            opportunities.extend(stat_arb_opportunities)
            
            # Cross-asset arbitrage
            cross_asset_opportunities = await self._detect_cross_asset_arbitrage(market_data)
            opportunities.extend(cross_asset_opportunities)
            
            # Temporal arbitrage
            temporal_opportunities = await self._detect_temporal_arbitrage(market_data)
            opportunities.extend(temporal_opportunities)
            
            # Filter by minimum criteria
            filtered_opportunities = [
                opp for opp in opportunities
                if opp.expected_profit >= self.config['arbitrage_detection']['min_spread']
                and opp.probability >= self.config['arbitrage_detection']['min_probability']
            ]
            
            # Sort by expected profit
            filtered_opportunities.sort(key=lambda x: x.expected_profit, reverse=True)
            
            logger.info(f"ðŸ’° Found {len(filtered_opportunities)} arbitrage opportunities")
            
            return filtered_opportunities[:10]  # Return top 10
            
        except Exception as e:
            logger.error(f"Error detecting arbitrage opportunities: {e}")
            return []
    
    async def _detect_statistical_arbitrage(self, market_data: Dict[str, Any]) -> List[ArbitrageOpportunity]:
        """Detect statistical arbitrage opportunities"""
        opportunities = []
        
        try:
            # Pairs trading opportunities
            assets = list(market_data.keys())
            
            for i, asset_a in enumerate(assets):
                for asset_b in assets[i+1:]:
                    # Check if we have price data for both assets
                    if 'price' not in market_data[asset_a] or 'price' not in market_data[asset_b]:
                        continue
                    
                    # Calculate price ratio
                    price_a = market_data[asset_a]['price']
                    price_b = market_data[asset_b]['price']
                    
                    if price_b == 0:
                        continue
                    
                    ratio = price_a / price_b
                    
                    # Historical ratio analysis (simplified)
                    # In production, use cointegration analysis
                    historical_ratio = 1.0  # Placeholder
                    spread = abs(ratio - historical_ratio) / historical_ratio
                    
                    if spread > 0.02:  # 2% spread threshold
                        expected_profit = spread * 0.5  # Assume 50% mean reversion
                        probability = min(0.9, spread * 10)  # Higher spread = higher probability
                        
                        opportunity = ArbitrageOpportunity(
                            opportunity_id=f"stat_arb_{asset_a}_{asset_b}_{int(datetime.now().timestamp())}",
                            asset_pair=(asset_a, asset_b),
                            spread=spread,
                            expected_profit=expected_profit,
                            probability=probability,
                            time_horizon="short",
                            entry_price_a=price_a,
                            entry_price_b=price_b,
                            exit_price_a=price_a * (1 - spread/2 if ratio > historical_ratio else 1 + spread/2),
                            exit_price_b=price_b * (1 + spread/2 if ratio > historical_ratio else 1 - spread/2),
                            risk_score=spread * 2,
                            liquidity_score=0.8,  # Simplified
                            execution_complexity="medium",
                            timestamp=datetime.now()
                        )
                        
                        opportunities.append(opportunity)
            
        except Exception as e:
            logger.error(f"Error in statistical arbitrage detection: {e}")
        
        return opportunities
    
    async def _detect_cross_asset_arbitrage(self, market_data: Dict[str, Any]) -> List[ArbitrageOpportunity]:
        """Detect cross-asset arbitrage opportunities"""
        opportunities = []
        
        try:
            # Example: ETF vs underlying arbitrage
            # SPY vs S&P 500 components (simplified)
            
            if 'SPY' in market_data and 'QQQ' in market_data:
                spy_price = market_data['SPY'].get('price', 0)
                qqq_price = market_data['QQQ'].get('price', 0)
                
                if spy_price > 0 and qqq_price > 0:
                    # Simplified ratio analysis
                    historical_spy_qqq_ratio = 1.5  # Placeholder
                    current_ratio = spy_price / qqq_price
                    spread = abs(current_ratio - historical_spy_qqq_ratio) / historical_spy_qqq_ratio
                    
                    if spread > 0.01:  # 1% threshold
                        opportunity = ArbitrageOpportunity(
                            opportunity_id=f"cross_asset_SPY_QQQ_{int(datetime.now().timestamp())}",
                            asset_pair=("SPY", "QQQ"),
                            spread=spread,
                            expected_profit=spread * 0.3,
                            probability=0.7,
                            time_horizon="medium",
                            entry_price_a=spy_price,
                            entry_price_b=qqq_price,
                            exit_price_a=spy_price * (1 - spread/3),
                            exit_price_b=qqq_price * (1 + spread/3),
                            risk_score=spread,
                            liquidity_score=0.9,
                            execution_complexity="low",
                            timestamp=datetime.now()
                        )
                        
                        opportunities.append(opportunity)
            
        except Exception as e:
            logger.error(f"Error in cross-asset arbitrage detection: {e}")
        
        return opportunities
    
    async def _detect_temporal_arbitrage(self, market_data: Dict[str, Any]) -> List[ArbitrageOpportunity]:
        """Detect temporal arbitrage opportunities"""
        opportunities = []
        
        try:
            # Example: Volatility arbitrage
            if 'VIX' in market_data:
                vix_level = market_data['VIX'].get('price', 20)
                
                # Historical VIX mean reversion
                historical_vix_mean = 20
                
                if abs(vix_level - historical_vix_mean) > 5:  # 5 point deviation
                    spread = abs(vix_level - historical_vix_mean) / historical_vix_mean
                    
                    opportunity = ArbitrageOpportunity(
                        opportunity_id=f"temporal_VIX_{int(datetime.now().timestamp())}",
                        asset_pair=("VIX", "VIX_MEAN"),
                        spread=spread,
                        expected_profit=spread * 0.4,
                        probability=0.6,
                        time_horizon="medium",
                        entry_price_a=vix_level,
                        entry_price_b=historical_vix_mean,
                        exit_price_a=historical_vix_mean,
                        exit_price_b=historical_vix_mean,
                        risk_score=spread * 1.5,
                        liquidity_score=0.7,
                        execution_complexity="high",
                        timestamp=datetime.now()
                    )
                    
                    opportunities.append(opportunity)
            
        except Exception as e:
            logger.error(f"Error in temporal arbitrage detection: {e}")
        
        return opportunities
    
    def get_optimization_status(self) -> Dict[str, Any]:
        """Get current optimization status"""
        return {
            'quantum_available': QUANTUM_AVAILABLE,
            'quantum_state': asdict(self.quantum_state) if self.quantum_state else None,
            'last_optimization': self.portfolio_history[-1] if self.portfolio_history else None,
            'total_optimizations': len(self.portfolio_history),
            'active_opportunities': len(self.arbitrage_opportunities),
            'performance_metrics': self.performance_metrics,
            'system_status': 'active',
            'last_update': datetime.now().isoformat()
        }
    
    def get_portfolio_history(self) -> List[Dict[str, Any]]:
        """Get portfolio optimization history"""
        return self.portfolio_history[-50:]  # Return last 50 optimizations
    
    def get_arbitrage_opportunities(self) -> List[Dict[str, Any]]:
        """Get current arbitrage opportunities"""
        return [asdict(opp) for opp in self.arbitrage_opportunities]

# Factory function
async def create_quantum_optimizer() -> QuantumPortfolioOptimizer:
    """Create and initialize the quantum portfolio optimizer"""
    optimizer = QuantumPortfolioOptimizer()
    return optimizer

if __name__ == "__main__":
    # Test the quantum optimizer
    async def test_quantum_optimizer():
        optimizer = await create_quantum_optimizer()
        
        # Test with sample data
        assets = ['SPY', 'QQQ', 'VIX', 'GLD', 'TLT']
        returns_data = pd.DataFrame(np.random.randn(252, len(assets)) * 0.01, columns=assets)
        
        result = await optimizer.optimize_portfolio(assets, returns_data)
        print(f"Optimization result: {result.optimization_method} with Sharpe ratio: {result.sharpe_ratio:.2f}")
    
    asyncio.run(test_quantum_optimizer())

